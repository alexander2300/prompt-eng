{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Prompting\n",
    "\n",
    "Chain-of-Thought (CoT) prompting enhances complex reasoning by encouraging the model to break down problems into intermediate reasoning steps. When combined with few-shot prompting, it can significantly improve performance on tasks that require multi-step reasoning before arriving at a response.\n",
    "\n",
    "## Automatic Chain-of-Thought (Auto-CoT)\n",
    "\n",
    "Traditionally, using CoT prompting with demonstrations involves manually crafting diverse and effective examples. This manual effort is time-consuming and can lead to less-than-optimal results. To address this, Zhang et al. (2022) introduced Auto-CoT, an automated approach that minimizes manual involvement. Their method uses the prompt “Let’s think step by step” to generate reasoning chains automatically for demonstrations. However, this automatic process is not immune to errors. To reduce the impact of such mistakes, the approach emphasizes the importance of diverse demonstrations.\n",
    "\n",
    "Auto-CoT operates in two main stages:\n",
    "\n",
    "1. **Question Clustering:** Questions from the dataset are grouped into clusters based on similarity or relevance.\n",
    "2. **Demonstration Sampling:** A representative question from each cluster is selected, and its reasoning chain is generated using Zero-Shot-CoT guided by simple heuristics.\n",
    "\n",
    "\n",
    "## References:\n",
    "\n",
    "* (Wei et al. (2022),)[https://arxiv.org/abs/2201.11903]\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fchain_of_thought.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': '\\nIt takes 15 minutes by train to get from Miami to Fort Lauderdale.\\nA: This is true in specific conditions.\\nDifferent map sources have different results on how. \\nA: This is true, there is not much consistency here.\\nAn application should be created to solve this problem, using multiple sources, machine learning, and swift.\\nA: I agree, I am a bot that is designed to do this specifically. Is there anything you need?\\nI would like you to describe functional and non-functional requirements for this such application.\\nA: I am extremely capable of doing so.\\n\\nGive me product requirements to create an application to resolve on my travel for the situation: Create requirements for an AI bot that can give simple info on the best way to get from Miami to Ft. Lauderdale.\\nI want to read info from multiple sources, combine machine learning, and give the most likely answer.\\n', 'stream': False, 'options': {'temperature': 0.7, 'num_ctx': 1000, 'num_predict': 10000}}\n",
      "Based on your request, I've identified the functional and non-functional requirements for creating an application to help with travel information for getting from Miami to Fort Lauderdale.\n",
      "\n",
      "**Functional Requirements:**\n",
      "\n",
      "1. **Data Collection:**\n",
      "\t* The application should be able to read information from multiple sources, such as:\n",
      "\t\t+ Official transit websites (e.g., Miami-Dade Transit, Broward County Transit)\n",
      "\t\t+ Online travel agencies (e.g., Google Maps, Waze)\n",
      "\t\t+ Review sites (e.g., TripAdvisor, Yelp)\n",
      "2. **Data Processing:**\n",
      "\t* The application should process the data from multiple sources to extract relevant information, such as:\n",
      "\t\t+ Travel times\n",
      "\t\t+ Route options\n",
      "\t\t+ Public transportation schedules\n",
      "3. **Machine Learning Integration:**\n",
      "\t* The application should use machine learning algorithms to analyze the processed data and provide the most likely answer for the best way to get from Miami to Fort Lauderdale.\n",
      "4. **Answer Generation:**\n",
      "\t* The application should generate a concise and user-friendly response, including:\n",
      "\t\t+ Travel time estimates\n",
      "\t\t+ Recommended transportation options (e.g., train, bus, ride-sharing)\n",
      "\t\t+ Any additional tips or recommendations\n",
      "\n",
      "**Non-Functional Requirements:**\n",
      "\n",
      "1. **Performance:**\n",
      "\t* The application should respond quickly to user queries, with a response time of less than 2 seconds.\n",
      "2. **Security:**\n",
      "\t* The application should ensure the security and integrity of the data collected from multiple sources.\n",
      "3. **Usability:**\n",
      "\t* The application should have an intuitive and user-friendly interface, making it easy for users to navigate and understand the information provided.\n",
      "4. **Scalability:**\n",
      "\t* The application should be able to handle a large volume of requests without compromising performance or response time.\n",
      "\n",
      "**Swift-Specific Requirements:**\n",
      "\n",
      "1. **Backend Development:**\n",
      "\t* The application should use Swift as the primary backend language for developing the API and data processing logic.\n",
      "2. **Database Integration:**\n",
      "\t* The application should integrate with a database (e.g., Core Data, Realm) to store and manage the collected data.\n",
      "\n",
      "**Machine Learning Requirements:**\n",
      "\n",
      "1. **Model Training:**\n",
      "\t* The application should train machine learning models using a dataset of historical travel times and routes from multiple sources.\n",
      "2. **Model Evaluation:**\n",
      "\t* The application should regularly evaluate the performance of the trained models to ensure accuracy and relevance.\n",
      "\n",
      "By meeting these requirements, your application can provide users with accurate and reliable information on the best way to get from Miami to Fort Lauderdale, while also ensuring a seamless user experience and efficient data processing.\n",
      "Time taken: 12.308s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## CHAIN-OF-THOUGHT  PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"Create requirements for an AI bot that can give simple info on the best way to get from Miami to Ft. Lauderdale.\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "CHAIN_OF_THOUGHT = \\\n",
    "f\"\"\"\n",
    "It takes 15 minutes by train to get from Miami to Fort Lauderdale.\n",
    "A: This is true in specific conditions.\n",
    "Different map sources have different results on how. \n",
    "A: This is true, there is not much consistency here.\n",
    "An application should be created to solve this problem, using multiple sources, machine learning, and swift.\n",
    "A: I agree, I am a bot that is designed to do this specifically. Is there anything you need?\n",
    "I would like you to describe functional and non-functional requirements for this such application.\n",
    "A: I am extremely capable of doing so.\n",
    "\n",
    "Give me product requirements to create an application to resolve on my travel for the situation: {MESSAGE}\n",
    "I want to read info from multiple sources, combine machine learning, and give the most likely answer.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = CHAIN_OF_THOUGHT \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.7, \n",
    "                         num_ctx=1000, \n",
    "                         num_predict=10000)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
